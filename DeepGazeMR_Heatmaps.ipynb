{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7ab380",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load in all of the libraries we need\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import psutil\n",
    "from itertools import islice \n",
    "\n",
    "## load in the model\n",
    "model = torch.hub.load('mtangemann/deepgazemr', 'DeepGazeMR', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4a5873",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This section trims the video down into smaller videos.\n",
    "## This is currently done to save memory - but I would like\n",
    "## to be able to run this code on larger videos and skip \n",
    "## this step entirely\n",
    "\n",
    "# Open the large video file for reading\n",
    "input_video = cv2.VideoCapture('Video_Game.mp4')\n",
    "\n",
    "# Get video properties (width, height, frames per second, etc.)\n",
    "frame_width = int(input_video.get(3))  # Width\n",
    "frame_height = int(input_video.get(4))  # Height\n",
    "fps = int(input_video.get(5))  # Frames per second\n",
    "total_frames = int(input_video.get(7))  # Total number of frames\n",
    "\n",
    "# Define the number of smaller videos you want to create\n",
    "num_videos = 4\n",
    "\n",
    "# Specify the output folder for the smaller videos\n",
    "output_folder = 'smaller_videos_4chunks'\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Calculate the number of frames per smaller video\n",
    "frames_per_video = total_frames // num_videos\n",
    "print(total_frames)\n",
    "print(num_videos)\n",
    "print(frames_per_video)\n",
    "print(frame_width)\n",
    "print(frame_height)\n",
    "\n",
    "# Loop through and create smaller videos\n",
    "for i in range(num_videos):\n",
    "    # Create a VideoWriter object for the smaller video\n",
    "    output_video = cv2.VideoWriter(os.path.join(output_folder, f'smaller_video_{i + 1}.mp4'), \n",
    "                                   cv2.VideoWriter_fourcc(*'mp4v'), \n",
    "                                   fps, \n",
    "                                   (frame_width, frame_height))\n",
    "    \n",
    "    # Write frames to the smaller video\n",
    "    for j in range(frames_per_video):\n",
    "        ret, frame = input_video.read()\n",
    "        if ret:\n",
    "            output_video.write(frame)\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    # Release the smaller video file\n",
    "    output_video.release()\n",
    "\n",
    "# Release the large video file\n",
    "input_video.release()\n",
    "\n",
    "# Close all OpenCV windows (if any)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cb1263",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Currently using cpu as the torch device because my CPU \n",
    "## has more memory than my GPU. Ideally this could be running\n",
    "## on Beocat with a large amount of GPU memory\n",
    "\n",
    "#if torch.cuda.is_available():\n",
    "    #device = torch.device('cuda')\n",
    "    ## Check the available GPU memory\n",
    "    #gpu_properties = torch.cuda.get_device_properties(device)\n",
    "    #gpu_memory = gpu_properties.total_memory / (1024**2)  # in megabytes\n",
    "    #print(f\"GPU Name: {gpu_properties.name}\")\n",
    "    #print(f\"GPU Memory: {gpu_memory} MB\")\n",
    "#else:\n",
    "    #print(\"CUDA is not available. Using CPU.\")\n",
    "\n",
    "cpu_memory = psutil.virtual_memory().available / (1024**2)  # in megabytes\n",
    "print(f\"CPU Memory: {cpu_memory} MB\")\n",
    "\n",
    "#device = torch.device('cuda')\n",
    "device = torch.device('cpu')\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ac10a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load up the video, and get the pixel information from \n",
    "## each frame into a torch object\n",
    "\n",
    "import skvideo.io\n",
    "\n",
    "video = skvideo.io.vread('smaller_videos_4chunks/smaller_video_2.mp4')\n",
    "video = torch.from_numpy(video).type(torch.float32)\n",
    "video = video.permute(0, 3, 1, 2) / 255.0\n",
    "video = video.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e878fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## set output directory\n",
    "output_directory = 'heatmap_frames_4chunks'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "## run the model on all frames (running on the \"video\" object \n",
    "## until there are no more frames), and save the outputs to \n",
    "## individual numpy files. These numpy files will be read by\n",
    "## VideoCreation.ipynb\n",
    "with torch.no_grad(): #torch.no_grad was added to hopefully reduce the amount of memory being used.\n",
    "    for i, prediction in enumerate(model.predict(video)):\n",
    "        if prediction is not None:\n",
    "            filename = f'{output_directory}/prediction_{i + vidframenumstart}.npy'\n",
    "            np.save(filename, prediction.cpu().numpy())\n",
    "\n",
    "            print(f\"Saved prediction {i} to {filename}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
